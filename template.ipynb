{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# PRE-EDA: DATA LOADING\r\n",
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Data reading and visualization\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "import plotly.express as px\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "%matplotlib inline\r\n",
    "\r\n",
    "# Statistical analysis\r\n",
    "from scipy.stats import norm\r\n",
    "\r\n",
    "# Scikit-learn\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\r\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\r\n",
    "\r\n",
    "# XGBoost & LightGBM\r\n",
    "from xgboost import XGBRegressor\r\n",
    "from lightgbm import LGBMRegressor\r\n",
    "\r\n",
    "import warnings\r\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CONFIGS\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "BASE_PATH = \"./\"\r\n",
    "\r\n",
    "rf_params = {\r\n",
    "    'n_estimators': 100,\r\n",
    "    'max_depth': 4,\r\n",
    "    'min_samples_split': 2,\r\n",
    "    'min_samples_leaf': 1\r\n",
    "    }\r\n",
    "\r\n",
    "xgb_params = {\r\n",
    "    'n_estimators': 1000,\r\n",
    "    'max_depth': 4,\r\n",
    "    'min_child_weight': 2,\r\n",
    "    'learning_rate': 0.01,\r\n",
    "    'subsample': 0.8,\r\n",
    "    'colsample_bytree': 0.8,\r\n",
    "    'booster': 'gbtree'\r\n",
    "    }\r\n",
    "\r\n",
    "lgb_params = {\r\n",
    "    'n_estimators': 1000,\r\n",
    "    'max_depth': 4,\r\n",
    "    'learning_rate': 0.01,\r\n",
    "    'subsample': 0.8,\r\n",
    "    'colsample_bytree': 0.8,\r\n",
    "    'objective': 'regression'\r\n",
    "    }"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## HELPER FUNCTIONS\r\n",
    "---"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Print dataset usage stats\r\n",
    "def print_info(df):\r\n",
    "    print(f\"\\nDataframe Shape: {df.shape}\")\r\n",
    "    print(f\"\\nDataframe Columns: {df.columns}\")\r\n",
    "    print(f\"\\nDataframe dtypes: \\n{df.dtypes.value_counts()}\")\r\n",
    "    print(\r\n",
    "        f\"\\nDataframe memory usage: {round(df.memory_usage().sum() / 1024**2, 2)} MB\")\r\n",
    "\r\n",
    "# Visualize misssing data\r\n",
    "def visualize_missing_data(df):\r\n",
    "    m_data = (df.isnull().sum() / len(df)) * 100\r\n",
    "    m_data = m_data.drop(m_data[m_data == 0].index).sort_values()\r\n",
    "    m_data = m_data.rename({'index': 'Feature', 0: 'Missing (%)'})\r\n",
    "\r\n",
    "    fig = px.bar(x=m_data.index, y=m_data,\r\n",
    "                 title='Missing Data by Feature', template='plotly_dark')\r\n",
    "    fig.update_xaxes(title_text=\"Feature\")\r\n",
    "    fig.update_yaxes(title_text=\"Missing (%)\")\r\n",
    "\r\n",
    "    fig.show()\r\n",
    "\r\n",
    "# Plot Histogram of dataset\r\n",
    "def plot_histogram(df, distline=True):\r\n",
    "    if distline:\r\n",
    "        fig = plt.figure(figsize=(15, 15))\r\n",
    "        for i, column in enumerate(df.columns):\r\n",
    "            plt.subplot(4, 4, i+1)\r\n",
    "            plt.title(column)\r\n",
    "            plt.xlabel(column)\r\n",
    "            sns.distplot(df[column], fit=norm)\r\n",
    "        plt.tight_layout()\r\n",
    "        plt.show()\r\n",
    "\r\n",
    "    if not distline:\r\n",
    "        fig = plt.figure(figsize=(15, 15))\r\n",
    "        hist = df.hist(figsize=(15, 15), bins=50)\r\n",
    "        plt.tight_layout()\r\n",
    "        plt.show()\r\n",
    "\r\n",
    "    plt.tight_layout()\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "# Fit data to model(s)\r\n",
    "def fit_robust_pipeline(model, X_train, y_train, X_test, y_test):\r\n",
    "    pipe = Pipeline([('scaler', RobustScaler()), ('model', model)])\r\n",
    "    pipe.fit(X_train, y_train)\r\n",
    "    score = pipe.score(X_test, y_test)\r\n",
    "\r\n",
    "    return round(score, 2)\r\n",
    "\r\n",
    "# Scaling Data\r\n",
    "def scale_data(scaler, df, feats_to_transform):\r\n",
    "    scaled_df = df.copy()\r\n",
    "    features = scaled_df[feats_to_transform]\r\n",
    "    features = scaler.fit_transform(features.values)\r\n",
    "\r\n",
    "    scaled_df[feats_to_transform] = features\r\n",
    "\r\n",
    "    return scaled_df\r\n",
    "\r\n",
    "for feat in cat_feats:\r\n",
    "    label_enc = LabelEncoder()\r\n",
    "    label_enc_df[feat] = label_enc.fit_transform(label_enc_df[feat])\r\n",
    "\r\n",
    "# OneHotEncoding\r\n",
    "for feat in cat_feats:\r\n",
    "    onehot_enc = OneHotEncoder(handle_unknown='ignore')\r\n",
    "    transformed = pd.DataFrame(onehot_enc.fit_transform(onehot_enc_df[feat].values.reshape(-1, 1)).toarray())\r\n",
    "    transformed.columns = [f\"{feat}_{i}\" for i in transformed.columns]\r\n",
    "    onehot_enc_df = onehot_enc_df.join(transformed)\r\n",
    "    onehot_enc_df.drop([feat], axis=1, inplace=True)\r\n",
    "\r\n",
    "\r\n",
    "# Encode Data\r\n",
    "def encode_data(df, encoder_type, feats_to_encode):\r\n",
    "    if encoder_type == 'Label':\r\n",
    "        for feat in cat_feats:\r\n",
    "            label_enc = LabelEncoder()\r\n",
    "            label_enc_df[feat] = label_enc.fit_transform(label_enc_df[feat])\r\n",
    "\r\n",
    "        return label_enc_df\r\n",
    "\r\n",
    "    elif encoder_type == 'OneHot':\r\n",
    "        for feat in cat_feats:\r\n",
    "            onehot_enc = OneHotEncoder(handle_unknown='ignore')\r\n",
    "            transformed = pd.DataFrame(onehot_enc.fit_transform(onehot_enc_df[feat].values.reshape(-1, 1)).toarray())\r\n",
    "            transformed.columns = [f\"{feat}_{i}\" for i in transformed.columns]\r\n",
    "            onehot_enc_df = onehot_enc_df.join(transformed)\r\n",
    "            onehot_enc_df.drop([feat], axis=1, inplace=True)\r\n",
    "        \r\n",
    "        return onehot_enc_df\r\n",
    "    else:\r\n",
    "        print(\"Invalid Encoder Type\")\r\n",
    "\r\n",
    "# Fit data to model(s)\r\n",
    "def evaluate_performance(X, Y, test_size=0.2, scale_data=False, scaler=None, feats_to_transform=None):\r\n",
    "    # Define models\r\n",
    "    rf = RandomForestRegressor(**rf_params)\r\n",
    "    xgb = XGBRegressor(**xgb_params)\r\n",
    "    lgb = LGBMRegressor(**lgb_params)\r\n",
    "\r\n",
    "    # Transform data\r\n",
    "    if scale_data:\r\n",
    "        X = scale_data(scaler, X, feats_to_transform)\r\n",
    "    \r\n",
    "    # Split data\r\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)  \r\n",
    "\r\n",
    "    # Pass models to pipeline\r\n",
    "    rf_score = fit_robust_pipeline(rf, X_train, y_train, X_test, y_test)\r\n",
    "    xgb_score = fit_robust_pipeline(xgb, X_train, y_train, X_test, y_test)\r\n",
    "    lgb_score = fit_robust_pipeline(lgb, X_train, y_train, X_test, y_test)\r\n",
    "\r\n",
    "    # Print scores\r\n",
    "    print(f\"Model Scores: \\n{'-'*25}\\n\")\r\n",
    "    print(f\"RandomForestRegressor Score: {rf_score}\")\r\n",
    "    print(f\"XGBRegressor Score: {xgb_score}\")\r\n",
    "    print(f\"LGBMRegressor Score: {lgb_score}\")\r\n",
    "\r\n",
    "    return rf, xgb, lgb\r\n",
    "\r\n",
    "# Plot feature importance\r\n",
    "def plot_feature_importance(features, title, model):\r\n",
    "    fig = px.bar(y=features, x=model.feature_importances_, template='plotly_dark')\r\n",
    "    fig.update_layout(title=f\"{title}\")\r\n",
    "    fig.update_xaxes(title_text=\"Feature Importance\")\r\n",
    "    fig.update_yaxes(title_text=\"Feature\")\r\n",
    "\r\n",
    "    fig.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EXPLORATORY DATA ANALYSIS (EDA)\r\n",
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DATA PREPROCESSING\r\n",
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## NORMALIZATION \r\n",
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FEATURE GENERATION\r\n",
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# FEATURE SELECTION\r\n",
    "----"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}